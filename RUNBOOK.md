# ğŸš€ Kafka Internals â€“ How to Run (First Time vs Subsequent Runs)

This project runs **Kafka, Kafka UI, and the Producer inside Docker**  
to avoid advertised listener and networking issues.

All services communicate using:

```

kafka:9092

````

---

## ğŸŸ¢ First-Time Setup (Fresh Machine / Fresh Clone)

> Use this **ONLY once** or when you want a completely clean state.

### 1ï¸âƒ£ Build the application JAR (fat JAR)

```bash
mvn clean package
````

âœ” Produces a runnable JAR with all Kafka dependencies.

Verify:

```bash
ls target/
```

You should see:

```
kafka-internals-1.0.0-SNAPSHOT.jar
```

---

### 2ï¸âƒ£ Start Kafka, Kafka UI, and Producer (clean state)

```bash
docker-compose down -v
docker-compose up -d --build
```

What this does:

* `down -v` â†’ removes old Kafka data, topics, offsets
* `--build` â†’ rebuilds producer Docker image
* Starts:

  * Zookeeper
  * Kafka broker
  * Kafka UI
  * Producer

â³ Wait ~30 seconds for Kafka to fully start.

---

### 3ï¸âƒ£ Create application topic (ONE TIME per clean start)

```bash
docker exec -it kafka bash
```

```bash
kafka-topics \
  --bootstrap-server kafka:9092 \
  --create \
  --topic order-events \
  --partitions 6 \
  --replication-factor 1
```

Verify:

```bash
kafka-topics --bootstrap-server kafka:9092 --list
```

Expected:

```
order-events
```

Exit container:

```bash
exit
```

---

### 4ï¸âƒ£ Verify everything is working

#### Producer logs

```bash
docker logs kafka-producer
```

Expected:

```
Produced event | orderId=... | partition=... | offset=...
```

#### Kafka UI

Open:

```
http://localhost:8080
```

* Cluster: **Online**
* Brokers: **1**
* Topics: `order-events`
* Messages tab loads correctly

âœ… **First-time setup complete**

---

## ğŸ” Subsequent Runs (Normal Development)

> Use this for **daily development**.

### 1ï¸âƒ£ Start everything (no data loss)

```bash
docker-compose up -d
```

âœ” Kafka keeps topics
âœ” Offsets preserved
âœ” Faster startup

---

### 2ï¸âƒ£ View logs if needed

```bash
docker logs kafka-producer
docker logs kafka
docker logs kafka-ui
```

---

### 3ï¸âƒ£ Stop everything (without deleting data)

```bash
docker-compose down
```

---

## ğŸ§ª Useful Verification Commands

### List topics

```bash
docker exec -it kafka kafka-topics \
  --bootstrap-server kafka:9092 \
  --list
```

---

### Describe topic

```bash
docker exec -it kafka kafka-topics \
  --bootstrap-server kafka:9092 \
  --describe \
  --topic order-events
```

---

### Consume messages manually

```bash
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic order-events \
  --from-beginning \
  --property print.partition=true \
  --property print.offset=true
```

---

## âš ï¸ Important Rules (Read This Once)

### âŒ Do NOT run producer from host JVM

Producer must run **inside Docker**, otherwise:

* Advertised listeners break
* Metadata becomes unreachable
* Kafka UI & producer time out

---

### âŒ Do NOT mix `localhost` and `kafka` addresses

Inside Docker:

```
kafka:9092 âœ…
localhost âŒ
```

---

### âŒ Do NOT use `docker-compose down -v` casually

That command:

* Deletes ALL topics
* Deletes ALL offsets
* Requires re-creating topics

Use it **only** when you want a clean slate.

---

## ğŸ§  Mental Model (Remember This)

```
Docker Network
  â”œâ”€â”€ Kafka (kafka:9092)
  â”œâ”€â”€ Producer
  â””â”€â”€ Kafka UI
```

One broker identity.
One advertised listener.
No ambiguity.

---

## âœ… Status Checklist

Before coding consumers, ensure:

* [x] Producer sends messages
* [x] Kafka UI shows messages
* [x] No timeouts
* [x] No advertised listener issues

---
